# Creditcardfraudprediction

### Credit card fraud prediction

#### Project Overview
```
The Credit Card Fraud Detection project is designed to identify fraudulent transactions using machine learning techniques. This classification model leverages historical transaction data to detect and flag potentially fraudulent activities, thereby enhancing security and reducing financial losses for credit card companies and their customers.
```
### Create a new Environment

```
conda create -p venv python==3.7 -y
```
#### Requirements
```
To run this project, you need the following software and libraries:
Python version 3.7 or higher
scikit-learn >= 1.0.0
numpy >= 1.21.0
pandas >= 1.3.0
imblearn >= 0.8.1
matplotlib >= 3.4.0
seaborn >= 0.11.0
IPython
```

### Software and tools requirements

1. [Github Account](https://github.com/TPK24/Creditcardfraudprediction)
2. [VSCodeIDE](https://code.visualstudio.com/)
3. [GitCLI](https://git-scm.com/)


### How to setup the project on local machine
```
Cloning the Repository
Local/folder/path>git clone https://github.com/TPK24/Creditcardfraudprediction.git
```
### Install Dependencies
```
You can install the packages using pip install -r requirements.txt
```
Dataset

https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud

Usage

1. Exploratory Data Analysis

   Tasks:

        Loading the Dataset.
        performing Statistical summaries.
        Visualizing data Distributions and Relationships.
   [Exploratory Data Analysis(EDA).ipynb](https://github.com/TPK24/Creditcardfraudprediction/blob/main/notebook/Exploratory%20Data%20Analysis(EDA).ipynb)

3. Data Preprocessing

   Tasks:

        Handle missing values.
        Feature engineering.
        Split the dataset into training and test sets.
   [Data Preprocessing.ipynb](https://github.com/TPK24/Creditcardfraudprediction/blob/main/notebook/Data%20Preprocessing.ipynb)

5. Model Training and Evaluation

    Tasks:

        Feature Scaling.
        Balancing the Dataset.
        Model training.
        Model Evaluation.
        Feature Importance.
        Pickling the data.
   
